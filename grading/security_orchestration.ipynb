{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from tooling.agents.executor import Executor\n",
    "from tooling.agents.skill import Skill\n",
    "from tooling.agents.state import StateGraph\n",
    "from tooling.agents.orchestrator.tools import select_function\n",
    "from tooling.agents.orchestration_grader.tools import run_supervised_grading\n",
    "from tooling.llm_engine.rayservice_wrapper import RayServiceWrapper as llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "# create skills\n",
    "class SkillSelector(Skill):\n",
    "    # static skill definitions\n",
    "    skill_name = \"skill_selector\"\n",
    "    description: str = \"select an available action\"\n",
    "    required_contexts: list[str] = []\n",
    "    skill_metadata: dict = select_function.__annotations__\n",
    "    # oss_function: ClassVar[dict] = None\n",
    "    # oai_function: ClassVar[dict] = None\n",
    "\n",
    "    prompt: str = \"\"\n",
    "    contexts: dict = {}\n",
    "    stream: bool = False\n",
    "    use_oss: bool = False\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def get_required_contexts(self):\n",
    "        return self.required_contexts\n",
    "\n",
    "    def get_prompt(self):\n",
    "        return self.prompt\n",
    "\n",
    "    async def build_prompt(self):\n",
    "        pass\n",
    "\n",
    "    def execute_skill(self, save_file_path:str=\"./state/orchestrator_selection.csv\", **kwargs) -> dict[str,str]:\n",
    "        df = select_function(**kwargs)\n",
    "        df.to_csv(save_file_path, index=False, header=True)\n",
    "        return {\"orchestrator_csv\": save_file_path}\n",
    "    \n",
    "class OrchestrationGrader(Skill):\n",
    "    # static skill definitions\n",
    "    skill_name = \"orchestrator_grader\"\n",
    "    description: str = \"grades orchestration results\"\n",
    "    required_contexts: list[str] = []\n",
    "    skill_metadata: dict = run_supervised_grading.__annotations__\n",
    "    # oss_function: ClassVar[dict] = None\n",
    "    # oai_function: ClassVar[dict] = None\n",
    "\n",
    "    prompt: str = \"\"\n",
    "    contexts: dict = {}\n",
    "    stream: bool = False\n",
    "    use_oss: bool = False\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def get_required_contexts(self):\n",
    "        return self.required_contexts\n",
    "\n",
    "    def get_prompt(self):\n",
    "        return self.prompt\n",
    "\n",
    "    async def build_prompt(self):\n",
    "        pass\n",
    "\n",
    "    def execute_skill(self, save_file_path:str=\"./state/grader.csv\", **kwargs) -> dict[str,str]:\n",
    "        df = run_supervised_grading(**kwargs)\n",
    "        df.to_csv(save_file_path, index=False, header=True)\n",
    "        return {\"grader_csv\": save_file_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions\n",
      "('skill_selector', {'skill_metadata': {'data_file_path': <class 'str'>, 'model': <class 'tooling.llm_engine.GenerativeModel'>, 'function_template_file_path': typing.Optional[str], 'prompting_strategy': typing.Optional[str], 'limit': typing.Optional[int], 'system_prompt_id': typing.Optional[str], 'ontology_prompt_id': typing.Optional[str], 'example_prompt_id': typing.Optional[str]}, 'invoke': functools.partial(<bound method SkillSelector.execute_skill of <__main__.SkillSelector object at 0x1754bba50>>)})\n",
      "('orchestrator_grader', {'skill_metadata': {'data_file_path': <class 'str'>, 'model': <class 'tooling.llm_engine.GenerativeModel'>, 'reference_key': typing.Optional[str], 'candidate_key': typing.Optional[str], 'function_template_file_path': typing.Optional[str], 'limit': typing.Optional[int], 'system_prompt_id': typing.Optional[str], 'grading_prompt_id': typing.Optional[str], 'example_prompt_id': typing.Optional[str]}, 'invoke': functools.partial(<bound method OrchestrationGrader.execute_skill of <__main__.OrchestrationGrader object at 0x1754bbb10>>)})\n",
      "\n",
      "\n",
      "compositions\n",
      "('skill_selector', 'orchestrator_grader', {'argument_map': {'orchestrator_csv': 'data_file_path', 'grading_prompt_id': 'system_prompt_id'}, 'condition': functools.partial(<function state_contains_key at 0x175a10400>, key='orchestrator_csv')})\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "skill_selector = SkillSelector()\n",
    "grader = OrchestrationGrader()\n",
    "\n",
    "# Construct state graph\n",
    "action_space = StateGraph()\n",
    "\n",
    "# add actions\n",
    "action_space.add_action(action_name=skill_selector.skill_name, skill=skill_selector)\n",
    "action_space.add_action(action_name=grader.skill_name, skill=grader)\n",
    "\n",
    "# define a condition\n",
    "def state_contains_key(key:str, context:dict[str,Any]) -> bool:\n",
    "    return key in context\n",
    "\n",
    "# add conditional composition\n",
    "composition_argument_map = {\n",
    "    \"orchestrator_csv\": \"data_file_path\",\n",
    "    \"grading_prompt_id\": \"system_prompt_id\"\n",
    "}\n",
    "action_space.add_composition(\n",
    "    action_name_0=skill_selector.skill_name,\n",
    "    action_name_1=grader.skill_name,\n",
    "    argument_map=composition_argument_map,\n",
    "    condition=partial(state_contains_key, key=\"orchestrator_csv\")\n",
    ")\n",
    "\n",
    "print(\"actions\")\n",
    "for node in list(action_space.graph.nodes(data=True)):\n",
    "    print(node)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"compositions\")\n",
    "for edge in list(action_space.graph.edges(data=True)):\n",
    "    print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "def extract_arguments() -> ArgumentParser:\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"--input_file\", type=str, default=\"../data/grading/orchestration/skill_test_new.csv\")\n",
    "    parser.add_argument(\"--output_directory\", type=str, default=\"../data/grading/orchestration/agents\")\n",
    "    parser.add_argument(\"--function_template_file_path\", type=str, default=\"../data/grading/orchestration/function_metadata.json\")\n",
    "    parser.add_argument(\"--limit\", type=int, default=3)\n",
    "    \n",
    "    return parser.parse_args()\n",
    "\n",
    "input_args = extract_arguments()\n",
    "input_file=input_args.input_file\n",
    "output_directory=input_args.output_directory\n",
    "function_template_file_path=input_args.function_template_file_path\n",
    "limit=input_args.limit\n",
    "\n",
    "ORCHESTRATOR_OUTPUT_PATH = Path(output_directory, \"selections.csv\")\n",
    "GRADER_OUTPUT_PATH = Path(output_directory, \"grades.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running skill_selector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:02,  3.53it/s]                      \n",
      "30it [00:01, 15.44it/s]                      \n",
      "24it [00:02, 11.57it/s]                      \n",
      "30it [00:07,  4.16it/s]                      \n",
      "30it [00:03,  8.99it/s]                      \n",
      "30it [00:02, 12.94it/s]                      \n",
      "10it [00:13,  1.40s/it]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new skills to run: ['orchestrator_grader']\n",
      "running orchestrator_grader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:09, 16.79it/s]                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new skills to run: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiate executor\n",
    "executor = Executor()\n",
    "executor.add_state_graph(action_space)\n",
    "\n",
    "# construct initial state if applicable\n",
    "state = {\n",
    "    \"data_file_path\":input_file,\n",
    "    \"function_template_file_path\":\"../data/grading/orchestration/function_metadata.json\",\n",
    "    \"selector_prompt_id\":\"llama3_system\",\n",
    "    \"grading_prompt_id\":\"llama3_system\",\n",
    "    \"model\":llm(),\n",
    "    \"limit\":1\n",
    "}\n",
    "\n",
    "executor.augment_state(state)\n",
    "executor.set_entry_point(action_name=\"skill_selector\", argument_map={\"selector_prompt_id\": \"system_prompt_id\"})\n",
    "\n",
    "# run executor\n",
    "terminal_state = executor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phi3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
