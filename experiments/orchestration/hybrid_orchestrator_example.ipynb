{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from numpy import percentile\n",
    "\n",
    "from typing import Optional\n",
    "from torch import device, tensor, Tensor, where\n",
    "from torch.cuda import is_available as cuda_is_available\n",
    "from torch_geometric.utils import remove_isolated_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for loading and filtering graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_filter(pyg_dataset, edge_weight_percentile:float, threshold:Optional[float]=None, node_attributes:Optional[list]=[]) -> float:\n",
    "    if not threshold:\n",
    "        edge_weights = []\n",
    "        for data in pyg_dataset:\n",
    "            edge_weights += data.edge_attr\n",
    "        threshold = percentile(edge_weights, edge_weight_percentile)\n",
    "        \n",
    "    for data in pyg_dataset:\n",
    "        edge_attr = tensor(data.edge_attr)\n",
    "        valid_edges = where(edge_attr > tensor(threshold))[0]\n",
    "        data.edge_index = data.edge_index[:,valid_edges]\n",
    "        data.edge_attr = edge_attr[valid_edges]\n",
    "        \n",
    "        # remove isolated nodes\n",
    "        data.edge_index, data.edge_attr, mask = remove_isolated_nodes(data.edge_index, data.edge_attr, num_nodes=data.x.shape[0])\n",
    "        data.x = data.x[mask,:]\n",
    "        for attribute in node_attributes:\n",
    "            if isinstance(data[attribute], list):\n",
    "                data[attribute] = [value for node_id, value in enumerate(data[attribute]) if mask[node_id]]\n",
    "            if isinstance(data[attribute], Tensor):\n",
    "                data[attribute] = data[attribute][mask]\n",
    "        \n",
    "    return threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained Models\n",
    "- LLM (transformer decoder)\n",
    "- Graph Neural Network (Graph Attention Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import float32\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle as pkl\n",
    "from torch import load as torch_load\n",
    "\n",
    "from tooling.llm_engine.gorilla_v2 import GorillaFunctionCalling as llm\n",
    "from torch_geometric.nn import global_max_pool, global_mean_pool\n",
    "from models.gnn.graph_classifier import GraphClassifier\n",
    "\n",
    "decoder_model = llm()\n",
    "\n",
    "skill_selector_directory = \"/home/azureuser/lbetthauser/models/orchestrator/gnn/model\"\n",
    "GRAPH_DEVICE = \"cuda:0\" if cuda_is_available else \"cpu\"\n",
    "\n",
    "with open(Path(skill_selector_directory, \"skill_map.json\"), \"r\") as f:\n",
    "    skill_mapping = json.load(f)\n",
    "reverse_skill_mapping = {v:k for k,v in skill_mapping.items()}\n",
    "\n",
    "with open(Path(skill_selector_directory, \"model_metadata.json\"), \"rb\") as f:\n",
    "    model_metadata = json.load(f)\n",
    "edge_filter_threshold = model_metadata.pop(\"edge_weight_threshold\")\n",
    "    \n",
    "# load model\n",
    "skill_selection_model = GraphClassifier(**model_metadata, pooling_layer=global_max_pool)\n",
    "skill_selection_model.load_state_dict(torch_load(Path(skill_selector_directory, \"model.pt\")), strict=True)\n",
    "skill_selection_model.eval()\n",
    "skill_selection_model.to(device(GRAPH_DEVICE))\n",
    "    \n",
    "print(skill_selection_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function Templates and Provide User Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_templates = [\n",
    "    {\n",
    "        \"name\": \"investigation_report\",\n",
    "        \"description\": \"Generates a structured incident report (Splunk Incident Report). The report includes a detailed timeline of actions taken and enriched context on what happened.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"work_notes\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The work notes about the splunk investigation.\"\n",
    "                },\n",
    "                \"output\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A splunk incident report.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"work_notes\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"investigation_summarizer\",\n",
    "        \"description\": \"Gets in progress work notes for an investigation contained in the chat history, fetches additional information based on the context, and generates a summary.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"work_notes\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The work notes about the splunk investigation.\"\n",
    "                },\n",
    "                \"output\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Natural language summary of the investigation.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"work_notes\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"finding_summarizer\",\n",
    "        \"description\": \"Gets in progress work notes for an investigation contained in the chat history, fetches additional information based on the context, and generates a summary.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"work_notes\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The work notes about the splunk investigation.\"\n",
    "                },\n",
    "                \"output\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Natural language summary of the finding.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"finding_notes\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"spl_editor\",\n",
    "        \"description\": \"Edits a user provided SPL query.\",\n",
    "        \"examples\": [\n",
    "            \"Edit this query to change the time frame, | rest /services/data/indexes | fields title | rename title AS index. Add a filter for title | rest /services/data/indexes.\",\n",
    "            \"Update, | rest /services/data/indexes | fields title | rename title AS index, to only get top 10 results.\"\n",
    "        ],\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"spl_query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The spl query the user wants to modify. SPL query from user question will start with 'search' or |.\"\n",
    "                },\n",
    "                \"intent\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A description of what the user would like to edit/change/fix/use/add/remove about the spl_query.\"\n",
    "                },\n",
    "                \"output\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The updated spl query.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"spl_query\", \"intent\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"spl_executor\",\n",
    "        \"description\": \"Executes a user provided splunk SPL query on the user's Splunk stack. Requires the spl_query to contain 'execute' spl, get results for spl, run, or run spl query.\",\n",
    "        \"examples\":  [\n",
    "            \"search src='10.9.165.*' OR dst='10.9.165.8\",\n",
    "            \"| rest /services/data/indexes | fields title | rename title AS index\"\n",
    "        ],\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"spl_query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A Splunk SPL query explicitely contained in the chat history. The SPL query must start with 'search' UNLESS its first command is contained in [tstats, rest, makeresults, searchtxn, datamodel, dbinspect, eventcount, from, gentimes, inputcsv, Inputlookup, loadjob, metadata, metasearch, mstats, multisearch, pivot, set.]\"\n",
    "                },\n",
    "                \"output\":{\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"additionalProperties\": True\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"spl_query\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"spl_detection_recommender\",\n",
    "        \"description\": \"Writes SPL to detect a user specified requested cyber security threat. If the user question does not define a specific threat, select another skill.\",\n",
    "        \"examples\": [\n",
    "            \"recommend a detection for 3CX Supply Chain Attack Network Indicators\",\n",
    "            \"give me SPL to detect ASL AWS Defense Evasion Delete CloudWatch Log Group.\",\n",
    "            \"Detections come from Splunk's Enterprise Security Content Updates (ESCU).\"\n",
    "        ],\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"intent\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A plain English sentence describing the intent of the desired detection. It should never have specific values but should refer to values generically (e.g. IP).\"\n",
    "                },\n",
    "                \"output\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The spl query for the threat dectection.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"intent\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"spl_writer\",\n",
    "        \"description\": \"Generates an SPL query from a user's natural language request when no reference SPL query is present. Returns a splunk spl query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"intent\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A short English sentence (15 words or less) describing the intent of the desired query. It should always start with 'This SPL query'. NEVER include time window or search time (e.g. 'in the past X days') even if the user specified.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"intent\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"conversation\",\n",
    "        \"description\": \"This function generates a natural language response to user query. Returns a response or answer to the user question.\",\n",
    "        \"examples\": [\n",
    "            \"What does SPL mean?\",\n",
    "            \"Can you summarize alerts?\",\n",
    "            \"What kind of detections can you recommend?\",\n",
    "            \"Can you execute spl?\"\n",
    "        ],\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"user_message\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The user's message.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"user_message\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "user_questions = [\n",
    "    \"How can I search for all incidents on my Splunk instance?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display functions\n",
    "print(\"(skill_name: description)\")\n",
    "for function_template in function_templates:\n",
    "    print(f\"({function_template['name']}: {function_template['description']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = decoder_model.format_conversations(\n",
    "    messages=[{\"role\": \"user\", \"content\": user_questions[0]}],\n",
    "    functions = [str(template) for template in function_templates]\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = decoder_model.generate_text(\n",
    "    requests=[[{\"role\": \"user\", \"content\": user_questions[0]}]],\n",
    "    functions = [str(template) for template in function_templates]\n",
    ")\n",
    "print(\"\\n\",responses[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tooling.huggingface_latent_representations.transformers.attention_featurization import extract_latent_feature_graph\n",
    "\n",
    "user_question = user_questions[0]\n",
    "\n",
    "# compute decoder attention\n",
    "input_ids, outputs  = decoder_model._extract_latent_features(prompt=prompt, max_tokens=1)\n",
    "\n",
    "# specify token ids for relevant subportion of the prompt\n",
    "template_start_ids = decoder_model.search_for_target_sequence(\"### Instruction: <<function>>\", prompt, input_ids)\n",
    "template_end_ids = decoder_model.search_for_target_sequence(\"<<question>>\", prompt, input_ids)\n",
    "input_end_ids = decoder_model.search_for_target_sequence(\"### Response: \", prompt, input_ids)\n",
    "# end_of_user_response = (outputs[0].view(-1)==100015).nonzero()[0].item()\n",
    "pairs_of_positions = [[template_start_ids+1, template_end_ids-2], [template_end_ids+2, input_end_ids-4]]\n",
    "\n",
    "# construct attention graph\n",
    "attention_graph = extract_latent_feature_graph(\n",
    "    input_ids=input_ids,\n",
    "    outputs=outputs,\n",
    "    position_index_a_endpoints=(template_start_ids+1, template_end_ids-2),\n",
    "    position_index_b_endpoints=(template_end_ids+2, input_end_ids-4)\n",
    ")\n",
    "\n",
    "# select skill with GNN\n",
    "print(attention_graph)\n",
    "_ = edge_filter( # filter edges below attention threshold\n",
    "    [attention_graph], # pytorch geometric graph\n",
    "    edge_weight_percentile=0, # ignored if threshold is specified\n",
    "    threshold=edge_filter_threshold, # use edge filtering value from pretraining\n",
    "    node_attributes=[\"ids\", \"node_types\"]\n",
    ")\n",
    "print(attention_graph)\n",
    "\n",
    "attention_graph.x = attention_graph.x.to(float32)\n",
    "attention_graph.batch = tensor([0]*attention_graph.x.shape[0])\n",
    "# attention_graph.ptr = tensor([0,attention_graph.x.shape[0]])\n",
    "attention_graph.to(GRAPH_DEVICE)\n",
    "out = skill_selection_model(node_features=attention_graph.x, edge_index=attention_graph.edge_index, batch=attention_graph.batch) # Perform a single forward pass.\n",
    "out.detach()\n",
    "pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "# output_skill_idx = skill_selection_model(attention_graph)\n",
    "skill_prediction = reverse_skill_mapping[pred.item()]\n",
    "del out\n",
    "\n",
    "print(\"\\n\", skill_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LLM with constrained generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_str = \"<<function>>{output_skill_name}(\".format(output_skill_name=skill_prediction)\n",
    "function_selection = decoder_model._generate_response(\n",
    "    prompt+skill_str # continuation where the skill name is included and expecting parameters\n",
    ")\n",
    "print(\"\\n\",skill_str+function_selection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phi3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
