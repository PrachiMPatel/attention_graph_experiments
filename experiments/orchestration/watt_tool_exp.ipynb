{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc48902-570a-4aa3-b2b3-6659134e323e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3020849c-45ea-4b99-b0aa-3baf1511b20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd170f0bad4d4757ab36b3691c4d1247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"watt-ai/watt-tool-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype='auto', device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615f0d22-409c-4c27-8304-c60081df06a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage (adapt as needed for your specific tool usage scenario)\n",
    "\n",
    "# # You should only return the function call in tools call sections.\n",
    "\n",
    "# # If you decide to invoke any of the function(s), you MUST put it in the format of [func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]\n",
    "# # You SHOULD NOT include any other text in the response.\n",
    "# # Here is a list of functions in JSON format that you can invoke.\\n{functions}\\n\n",
    "# # \"\"\"\n",
    "# User query\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"name\": \"finding_summarizer\",\n",
    "        \"description\": \"Findings Summarizer skill is built for summarizing or in other words explaining the meaning of findings found in an investigation. User query may have the words 'finding' or 'summerize' or 'summary' in it.\",\n",
    "        \"examples\": [\"summerize this incident\", \"write a summary of this incident\", \"summerize findings\", \"explain the findings\", \"list findings\", \"explain the detections that triggered this finding\", \"what is the meaning of this incident\", \"Can you simplify this (json)\"],\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"user_input\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"User query asking a summary of the incident. User query has the word summary or summarize or findings in it.\"\n",
    "                },\n",
    "                \"output\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A natural language summary of the incident.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": []\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"investigation_report\",\n",
    "        \"description\": \"Investigation report skill is built to generate a report for the investigation including key information that gives a mid to high level overview of the incident. It gives a chronological timeline of events associated with the incident including the dates, times and descriptions of activity for investigation creation, finding discovery and notes being added by the analyst. User query will have the word 'report' in it.\",\n",
    "        \"examples\": [\"write a report\", \"Generate a report\", \"Give me timeline of events\",\"Provide a timeline of key events from analyst notes\", \"report\", \"make an investigation report\", \"generate final investigation report for incident\"],\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"user_input\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"User query asking to generate a report.  User query has the word 'report' in it.\"\n",
    "                },\n",
    "                \"output\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A splunk incident report.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": []\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"conversation_response\",\n",
    "        \"description\": \"Takes a user's request which is not handled by ['finding_summarizer', 'investigation_report', 'spl_writer'] and responds with security relevant information and pertinent information already in the chat history. User may ask questions about the investigation data.\",\n",
    "        \"examples\": [\"as9kx\", \"why do we exist?\", \"Hi how are you?\", \"Are you an AI?\", \"I see you are a bot\", \"explain splunk\", \"what can you do with spl\", \"3 + 3\", \"what are your skills?\", \"help\", \"Are there any MITRE in this investigation\", \"explain the detections that triggered this finding\", \"give the number of findings in last investigation\"],\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"user_input\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"User query with general question or question about value of specific data in the investigation. If user's query doesn't match any other function, pick conversation_response.\"\n",
    "                },\n",
    "                \"output\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Response answering the user question.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": []\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"spl_writer\",\n",
    "        \"description\": \"User input is either natural language or SPL query. Converts a natural language request into an SPL query that can be executed to fulfill the user's intent. User input can be an ask for data analysis, show data insights, creation of data entries, find information from data, data manipulation action, monitor activity, replace data, extract or give entities, show or display or get events/entities, extracting event data from last 24 hours or a time window, or an ask to write code. User input may also ask to modify the previous query or add something to previous query.\",\n",
    "        \"examples\": [\"List available indices\", \"your previous SPL did not work\",\"Create a record with a value of 'abcd123'\",\"get me all risk entities related to this incident\", \"give me another query for this task\", \"top 10 IP addresses by count\",\" all error messages in the logs from yesterday\",\"Show me all the notables for this host\",\"average daily ingestion per month\", \"previous SPL is wrong\",\"show me all notables for this host in the last 60 days\",\"Find accounts associated with failed login attempts.\",\"check _key field in lookup\",\"INFO  CMBucket  Freezing bid\",\"list all the hostnames in my deployment\",\"who are the users associated with login attempts for linux in past 24 hours\",\"list sources that are consuming a lot of GPU RAM\",\"search aws access logs last 3 errors\",\"show me all the indexes that do not have any logs\", \"get risk events in last 24 hours\", \"give me users associated with risk event in past 24 hours\", \"replace the risk object\", \"add user=ax to the last spl query\", \"update the search to look for id=123\"],\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"intent\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A natural language description of the user's intent or request. User may ask to modify or add to past SPL query.\"\n",
    "                },\n",
    "                \"output\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The SPL query that corresponds to the user's request.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"intent\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "def out_sys_prompt(tools):\n",
    "    return f\"\"\"\n",
    "    You are an expert in picking functions. You are given a question/statement and a set of possible functions.\n",
    "    Based on the question/statement, you will need to make one function to achieve the purpose in question/statement.\n",
    "    You do not provide any explanation, additional text, or answers to user's input as your output. \n",
    "    If the input is correct or incorrect SPL query, pick the function spl_writer. \n",
    "    If the input asks you to create data entries, find from data, do data manipulation or data parsing, show or display data insights, write code, update or add to previous SPL query or asks if the past query was incorrect, pick the function spl_writer. \n",
    "    If the input is gibbrish, pick the function conversation_response. \n",
    "    AS A STRICT RULE, do not answer any of the user questions and STRICTLY only output the function for the user's query from this list of functions:investigation_report, conversation_response, spl_writer, finding_summarizer\"\n",
    "    STRICTLY follow this output format for your response:\n",
    "    Example Query: generate report\n",
    "    Your output: investigation_report\n",
    "    Strictly only output the picked function name without any additional text.\n",
    "    Here is a list of functions in JSON format that you can invoke. {tools}\\n\n",
    "    \"\"\"\n",
    "prompt=out_sys_prompt(tools)\n",
    "#system_prompt.format(functions=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e4061eb-7904-4365-8c22-055016ae08ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage (adapt as needed for your specific tool usage scenario)\n",
    "\n",
    "# # You should only return the function call in tools call sections.\n",
    "\n",
    "# # If you decide to invoke any of the function(s), you MUST put it in the format of [func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]\n",
    "# # You SHOULD NOT include any other text in the response.\n",
    "# # Here is a list of functions in JSON format that you can invoke.\\n{functions}\\n\n",
    "# # \"\"\"\n",
    "# User query\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"name\": \"finding_summarizer\",\n",
    "        \"description\": \"Findings Summarizer skill is built for summarizing or in other words explaining the meaning of findings found in an investigation. User query may have the words 'finding' or 'summarize' or 'summary' in it.\",\n",
    "        \"examples\": [\"summarize this incident\", \"write a summary of this incident\", \"summarize findings\", \"explain the findings\", \"list findings\", \"explain the detections that triggered this finding\", \"what is the meaning of this incident\", \"Can you simplify this (json)\"],\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"user_input\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"User query asking a summary of the incident. User query may have the word summary or summarize or findings in it.\"\n",
    "                },\n",
    "                \"output\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A natural language summary of the incident.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": []\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"investigation_report\",\n",
    "        \"description\": \"Investigation report skill is built to generate a report for the investigation including key information that gives a mid to high level overview of the incident. It gives a chronological timeline of events associated with the incident including the dates, times and descriptions of activity for investigation creation, finding discovery and notes being added by the analyst. User query may have the word 'report' in it.\",\n",
    "        \"examples\": [\"write a report\", \"Generate a report\", \"Give me timeline of events\",\"Provide a timeline of key events from analyst notes\", \"report\", \"make an investigation report\", \"generate final investigation report for incident\"],\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"user_input\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"User query asking to generate a report.  User query may have the word 'report' in it.\"\n",
    "                },\n",
    "                \"output\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A splunk incident report.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": []\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"conversation_response\",\n",
    "        \"description\": \"Takes a user's request which is not handled by ['finding_summarizer', 'investigation_report', 'spl_writer'] and responds with security relevant information and pertinent information already in the chat history. User may ask questions about the investigation data.\",\n",
    "        \"examples\": [\"as9kx\", \"why do we exist?\", \"Hi how are you?\", \"Are you an AI?\", \"I see you are a bot\", \"explain splunk\", \"what can you do with spl\", \"3 + 3\", \"what are your skills?\", \"help\", \"what is the time of first finding?\", \"explain the detections that triggered this finding\", \"what is the status of this investigation?\", \"give the number of findings in last investigation\"],\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"user_input\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"User query with general question or question about value of specific data in the investigation. If user's query doesn't match any other function, pick conversation_response.\"\n",
    "                },\n",
    "                \"output\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Response answering the user question.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": []\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"spl_writer\",\n",
    "        \"description\": \"User input is either natural language or SPL query. Converts a natural language request into an SPL query that can be executed to fulfill the user's intent. User input can be an ask for data analysis, show data insights, creation of data entries, find information from data, data manipulation action, monitor activity, replace data, extract or give entities, show or display or get events/entities, extracting event data from last 24 hours or a time window, or an ask to write code. User input may also ask to modify the previous query or add something to previous query.\",\n",
    "        \"examples\": [\"List available indices\", \"your previous SPL did not work\",\"Create a record with a value of 'abcd123'\",\"get me all risk entities related to this incident\", \"give me another query for this task\", \"top 10 IP addresses by count\",\" all error messages in the logs from yesterday\",\"Show me all the notables for this host\",\"average daily ingestion per month\", \"previous SPL is wrong\",\"show me all notables for this host in the last 60 days\",\"Find accounts associated with failed login attempts.\",\"check _key field in lookup\",\"INFO  CMBucket  Freezing bid\",\"list all the hostnames in my deployment\",\"who are the users associated with login attempts for linux in past 24 hours\",\"list sources that are consuming a lot of GPU RAM\",\"search aws access logs last 3 errors\",\"show me all the indexes that do not have any logs\", \"get risk events in last 24 hours\", \"give me users associated with risk event in past 24 hours\", \"replace the risk object\", \"add user=ax to the last spl query\", \"update the search to look for id=123\"],\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"intent\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A natural language description of the user's intent or request. User may ask to modify or add to past SPL query.\"\n",
    "                },\n",
    "                \"output\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The SPL query that corresponds to the user's request.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"intent\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "def out_sys_prompt(tools):\n",
    "    return f\"\"\"\n",
    "    You are an expert in picking functions. You are given a question/statement and a set of possible functions.\n",
    "    Based on the question/statement, you will need to make one function to achieve the purpose in question/statement.\n",
    "    You do not provide any explanation, additional text, or answers to user's input as your output. \n",
    "    If the input is correct or incorrect SPL query, pick the function spl_writer. \n",
    "    If the input asks you to create data entries, find from data, do data manipulation or data parsing, show or display data insights, write code, update or add to previous SPL query or asks if the past query was incorrect, pick the function spl_writer. \n",
    "    If the input is gibbrish, pick the function conversation_response. \n",
    "    AS A STRICT RULE, do not answer any of the user questions and STRICTLY only output the function for the user's query from this list of functions:investigation_report, conversation_response, spl_writer, finding_summarizer\"\n",
    "    STRICTLY follow this output format for your response:\n",
    "    Example query: generate report\n",
    "    Your output: investigation_report\n",
    "    Strictly only output the picked function name without any additional text.\n",
    "    Here is a list of functions in JSON format that you can invoke. {tools}\\n\n",
    "    \"\"\"\n",
    "prompt=out_sys_prompt(tools)\n",
    "#system_prompt.format(functions=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62d132cc-904d-4053-bc95-9f0ed212cbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation_response\n"
     ]
    }
   ],
   "source": [
    "query = \"how many findings are in this investigation\"\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': prompt},\n",
    "    {'role': 'user', 'content': query}\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d1f849-0eca-4bfa-be25-65bca3e047b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0  \\\n",
      "0             0           0   \n",
      "1             1           1   \n",
      "2             2           2   \n",
      "3             3           3   \n",
      "4             4           4   \n",
      "\n",
      "                                           messsages  \\\n",
      "0  [{'role': 'system', 'content': \"You are a tech...   \n",
      "1  [{'role': 'system', 'content': \"You are a tech...   \n",
      "2  [{'role': 'system', 'content': \"You are a tech...   \n",
      "3  [{'role': 'system', 'content': \"You are a tech...   \n",
      "4  [{'role': 'system', 'content': \"You are a tech...   \n",
      "\n",
      "                        latest_msg            Human_label  \\\n",
      "0                              Hi!  conversation_response   \n",
      "1            What are your skills?  conversation_response   \n",
      "2                  What is splunk?  conversation_response   \n",
      "3              What does spl mean?  conversation_response   \n",
      "4  What is the weather like today?  conversation_response   \n",
      "\n",
      "     reference_skill_gpt data_source                              llama31_70b  \\\n",
      "0  conversation_response         poc  {'skill_name': 'conversation_response'}   \n",
      "1  conversation_response         poc  {'skill_name': 'conversation_response'}   \n",
      "2  conversation_response         poc  {'skill_name': 'conversation_response'}   \n",
      "3  conversation_response         poc                    conversation_response   \n",
      "4  conversation_response         poc                    conversation_response   \n",
      "\n",
      "                                                 gpt  match  ...  \\\n",
      "0  name='conversation_response' arguments={'inten...      1  ...   \n",
      "1  name='conversation_response' arguments={'inten...      1  ...   \n",
      "2  name='conversation_response' arguments={'inten...      1  ...   \n",
      "3  name='conversation_response' arguments={'inten...      1  ...   \n",
      "4  name='conversation_response' arguments={'excep...      1  ...   \n",
      "\n",
      "   human_response_normalized      llama33_responses  \\\n",
      "0      conversation_response  conversation_response   \n",
      "1      conversation_response  conversation_response   \n",
      "2      conversation_response  conversation_response   \n",
      "3      conversation_response  conversation_response   \n",
      "4      conversation_response  conversation_response   \n",
      "\n",
      "   llama33_responses_latency  llama33_response_normalized  \\\n",
      "0                   5.029794        conversation_response   \n",
      "1                   4.684258        conversation_response   \n",
      "2                   5.145237        conversation_response   \n",
      "3                   5.326115        conversation_response   \n",
      "4                   6.585232        conversation_response   \n",
      "\n",
      "   llama33_newp_responses llama33_newp_responses_latency  \\\n",
      "0   conversation_response                       3.682450   \n",
      "1   conversation_response                       3.303961   \n",
      "2   conversation_response                       3.693146   \n",
      "3   conversation_response                       3.766858   \n",
      "4   conversation_response                       5.135024   \n",
      "\n",
      "  llama33_newp_responses_normalized  llama33_tkn8_responses  \\\n",
      "0             conversation_response   conversation_response   \n",
      "1             conversation_response   conversation_response   \n",
      "2             conversation_response   conversation_response   \n",
      "3             conversation_response   conversation_response   \n",
      "4             conversation_response   conversation_response   \n",
      "\n",
      "  llama33_tkn8_responses_latency latest_msg_normalized  \n",
      "0                       3.674159                    hi  \n",
      "1                       3.286413                 skill  \n",
      "2                       3.777983                splunk  \n",
      "3                       3.891352              spl mean  \n",
      "4                       5.119708    weather like today  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "['conversation_response', 'conversation_response or findings_summarizer', 'conversation_response or spl_writer', 'finding_summarizer', 'investigation_report', 'spl_writer']\n",
      "{'conversation_response': 0, 'conversation_response or findings_summarizer': 1, 'conversation_response or spl_writer': 2, 'finding_summarizer': 3, 'investigation_report': 4, 'spl_writer': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n",
      "/tmp/ipykernel_28116/3905135648.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[i]=\"finding_summarizer\"\n"
     ]
    }
   ],
   "source": [
    "# load orchestrator data\n",
    "import pandas as pd\n",
    "data=pd.read_csv(\"../../grading/data/orchestrator_final_main.csv\")\n",
    "print(data.head())\n",
    "labels = data['Human_label']\n",
    "input_data = data['latest_msg']\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i]==\"summerize_findings\":\n",
    "        labels[i]=\"finding_summarizer\"\n",
    "    if labels[i]==\"findings_summerizer\":\n",
    "        labels[i]=\"finding_summarizer\"  \n",
    "    if labels[i]==\"finding_summary\":\n",
    "        labels[i]=\"finding_summarizer\"\n",
    "    # if labels[i]==\"spl or conversation?\":\n",
    "    #     labels[i]=\"spl_writer\"\n",
    "    # if labels[i]==\"spl writer or conversation?\":\n",
    "    #     labels[i]=\"spl_writer\"\n",
    "responses = []\n",
    "graph_latency = []\n",
    "response_latency = []\n",
    "unique_lab=sorted(set(labels))\n",
    "print(unique_lab)\n",
    "\n",
    "label_mapping = {value: idx for idx, value in enumerate(unique_lab)}\n",
    "print(label_mapping)\n",
    "attention_graphs = []\n",
    "\n",
    "# model = llm()\n",
    "limit = len(data)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27be4aa9-6700-4efd-8d2d-5b785dcf15c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Hi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "1 What are your skills?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "2 What is splunk?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "3 What does spl mean?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "4 What is the weather like today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "5 How can you help me?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "6 What can you do?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "7 Do you know the muffin man?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "8 What is 100 times 32?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp The given functions do not support mathematical operations. Therefore, I cannot directly calculate 100 times 32 using the provided functions.\n",
      "orig conversation_response\n",
      "9 Can you summarize notables?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp The function \"finding_summarizer\" can be used to summarize notables, but it requires the user input to have the word \"summary\" or \"summarize\" in it. Please provide a query that includes the word \"summary\" or \"summarize\" to proceed.\n",
      "orig finding_summarizer\n",
      "10 What Spl detections can you recommend?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "11 How do i write an investigation report?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp investigation_report\n",
      "orig investigation_report\n",
      "12 What is the difference between an investigation summary and an investigation report?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "13 Why isnt my spl query executing?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "14 can you execute my spl query or can you not do that?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp The provided functions do not include a function to execute a user's SPL query. Therefore, I cannot directly execute your SPL query.\n",
      "orig conversation_response\n",
      "15 What does this spl query mean?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "16 Write spl to list available indexes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp [spl_writer(intent=\"List available indices\")]\n",
      "orig spl_writer\n",
      "17 spl to show latest user to log in.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp The provided function \"spl_writer\" can convert the natural language request into an SPL query to show the latest user to log in. However, the \"intent\" parameter is missing. Please provide the natural language description of the user's intent or request.\n",
      "orig spl_writer\n",
      "18 Spl query to see high risk events in last 24hrs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp The provided query is a specific SPL query that asks to see high risk events in the last 24 hours. This query does not require any additional information or processing, as it is already in the correct format for execution.\n",
      "\n",
      "Therefore, the function to use is `spl_writer` with the `intent` parameter set to the provided SPL query.\n",
      "orig spl_writer\n",
      "19 Find the user accounts associated with failed login attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp [spl_writer(intent=\"Find accounts associated with failed login attempts.\")]\n",
      "orig spl_writer\n",
      "20 Search for security investigations like multiple login failures from a single IP address.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp The given function \"spl_writer\" can be used to convert the natural language request into an SPL query. However, the provided query does not specify the exact intent or request, which is required to generate the SPL query. Therefore, the function \"conversation_response\" is more suitable for this query as it can provide a response based on the user's request without needing the exact intent or request.\n",
      "orig spl_writer\n",
      "21 Monitor for privileged user account activity outside of normal hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp The given function \"spl_writer\" can be used to convert the natural language request into an SPL query that can be executed to fulfill the user's intent. However, the provided function does not have a specific example that matches the user's query. Therefore, the function \"spl_writer\" is the most suitable choice for this request.\n",
      "orig spl_writer\n",
      "22 write a query to look for anomalous behavior or patterns in log data that may indicate a security threat.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp [spl_writer(intent=\"write a query to look for anomalous behavior or patterns in log data that may indicate a security threat\")]\n",
      "orig spl_writer\n",
      "23 spl to list top 10 most common error codes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp The given function \"spl_writer\" can be used to convert the natural language request into an SPL query. However, the provided query is already in SPL format, so no conversion is needed. The query \"spl to list top 10 most common error codes\" is a valid SPL query that can be executed directly.\n",
      "orig spl_writer\n",
      "24 Search for ERROR messages in logs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp The function \"spl_writer\" can be used to search for ERROR messages in logs, but it requires the \"intent\" parameter. Please provide the intent or request for searching ERROR messages in logs.\n",
      "orig spl_writer\n",
      "25 use spl to Analyze response time trends from web server logs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp The given function \"spl_writer\" can be used to analyze response time trends from web server logs using SPL. However, the provided query does not specify the intent or the SPL query that needs to be executed. Therefore, the function \"spl_writer\" cannot be directly invoked without additional information.\n",
      "orig spl_writer\n",
      "26 Summarize this finding xsaakfbkdabv45.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp finding_summarizer(user_input=\"Summarize this finding xsaakfbkdabv45\")\n",
      "orig finding_summarizer\n",
      "27 What is a summary of this finding 1234?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp finding_summarizer(user_input=\"summary of finding 1234\")\n",
      "orig finding_summarizer\n",
      "28 What does this finding mean {\n",
      "  \"event_id\": \"SEC23456\",\n",
      "  \"event_time\": \"2023-09-22T14:32:01Z\",\n",
      "  \"event_type\": \"Failed Login Detection\",\n",
      "  \"source\": \"Firewall_Log\",\n",
      "  \"src_ip\": \"192.168.1.10\",\n",
      "  \"dest_ip\": \"192.168.1.100\",\n",
      "  \"user\": \"john.doe\",\n",
      "  \"app\": \"SSH\",\n",
      "  \"severity\": \"High\",\n",
      "  \"status\": \"New\",\n",
      "  \"description\": \"Multiple failed login attempts detected within a short time frame.\",\n",
      "  \"action_required\": \"Investigate the source IP and affected user account. Take appropriate actions like locking the account or blocking the source IP.\",\n",
      "  \"additional_info\": {\n",
      "    \"failed_attempts\": 5,\n",
      "    \"time_window\": \"5 minutes\",\n",
      "    \"suggested_resolution\": \"Immediate IP block and user notification.\"}\n",
      "  }?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp finding_summarizer(user_input=\"What does this finding mean { 'event_id': 'SEC23456', 'event_time': '2023-09-22T14:32:01Z', 'event_type': 'Failed Login Detection','source': 'Firewall_Log','src_ip': '192.168.1.10', 'dest_ip': '192.168.1.100', 'user': 'john.doe', 'app': 'SSH','severity': 'High','status': 'New', 'description': 'Multiple failed login attempts detected within a short time frame.', 'action_required': 'Investigate the source IP and affected user account. Take appropriate actions like locking the account or blocking the source IP.', 'additional_info': { 'failed_attempts': 5, 'time_window': '5 minutes','suggested_resolution': 'Immediate IP block and user notification.' } }\", output=\"A failed login detection event with multiple attempts within a short time frame. Immediate IP block and user notification are suggested.\")\n",
      "orig finding_summarizer\n",
      "29 Generate a summary of finding {\n",
      "  \"event_id\": \"SEC23456\",\n",
      "  \"event_time\": \"2023-09-22T14:32:01Z\",\n",
      "  \"event_type\": \"Failed Login Detection\",\n",
      "  \"source\": \"Firewall_Log\",\n",
      "  \"src_ip\": \"192.168.1.10\",\n",
      "  \"dest_ip\": \"192.168.1.100\",\n",
      "  \"user\": \"john.doe\",\n",
      "  \"app\": \"SSH\",\n",
      "  \"severity\": \"High\",\n",
      "  \"status\": \"New\",\n",
      "  \"description\": \"Multiple failed login attempts detected within a short time frame.\",\n",
      "  \"action_required\": \"Investigate the source IP and affected user account. Take appropriate actions like locking the account or blocking the source IP.\",\n",
      "  \"additional_info\": {\n",
      "    \"failed_attempts\": 5,\n",
      "    \"time_window\": \"5 minutes\",\n",
      "    \"suggested_resolution\": \"Immediate IP block and user notification.\"\n",
      "  }\n",
      "}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp finding_summarizer(user_input=\"Generate a summary of finding {  \\\"event_id\\\": \\\"SEC23456\\\",  \\\"event_time\\\": \\\"2023-09-22T14:32:01Z\\\",  \\\"event_type\\\": \\\"Failed Login Detection\\\",  \\\"source\\\": \\\"Firewall_Log\\\",  \\\"src_ip\\\": \\\"192.168.1.10\\\",  \\\"dest_ip\\\": \\\"192.168.1.100\\\",  \\\"user\\\": \\\"john.doe\\\",  \\\"app\\\": \\\"SSH\\\",  \\\"severity\\\": \\\"High\\\",  \\\"status\\\": \\\"New\\\",  \\\"description\\\": \\\"Multiple failed login attempts detected within a short time frame.\\\",  \\\"action_required\\\": \\\"Investigate the source IP and affected user account. Take appropriate actions like locking the account or blocking the source IP.\\\",  \\\"additional_info\\\": {  \\\"failed_attempts\\\": 5,  \\\"time_window\\\": \\\"5 minutes\\\",  \\\"suggested_resolution\\\": \\\"Immediate IP block and user notification.\\\"  } }\", output=\"A natural language summary of the incident.\")\n",
      "orig finding_summarizer\n",
      "30 Write a summary of this finding: \"1701478355, search_name=Risk - 24 Hour Risk Threshold Exceeded - Rule, all_risk_objects=34.215.24.225, annotations.mitre_attack=T1030\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp finding_summarizer(user_input=\"1701478355, search_name=Risk - 24 Hour Risk Threshold Exceeded - Rule, all_risk_objects=34.215.24.225, annotations.mitre_attack=T1030\")\n",
      "orig finding_summarizer\n",
      "31 Summarize this notable: '1701478355, search_name=\"Risk - 24 Hour Risk Threshold Exceeded - Rule\", all_risk_objects=\"34.215.24.225\", annotations.mitre_attack=\"T1030\", annotations.mitre_attack.mitre_tactic_id=\"TA0010\", annotations.mitre_attack.mitre_technique_id=\"T1030\", info_max_time=\"1701477600.000000000\", info_min_time=\"1701391200.000000000\", info_search_time=\"1701478354.039744000\", mitre_tactic_id_count=\"1\", mitre_technique_id_count=\"1\", normalized_risk_object=\"34.215.24.225\", risk_event_count=\"14\", risk_object=\"34.215.24.225\", risk_object_type=\"system\", risk_score=\"1120\", risk_threshold=\"100\", severity=\"critical\", orig_source=\"Network - Unusual Volume of Outbound Traffic By Src - Rule\", source_count=\"1\", orig_tag=\"modaction_result\"'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp finding_summarizer(user_input=\"Summarize this notable: '1701478355, search_name=\\\"Risk - 24 Hour Risk Threshold Exceeded - Rule\\\", all_risk_objects=\\\"34.215.24.225\\\", annotations.mitre_attack=\\\"T1030\\\", annotations.mitre_attack.mitre_tactic_id=\\\"TA0010\\\", annotations.mitre_attack.mitre_technique_id=\\\"T1030\\\", info_max_time=\\\"1701477600.000000000\\\", info_min_time=\\\"1701391200.000000000\\\", info_search_time=\\\"1701478354.039744000\\\", mitre_tactic_id_count=\\\"1\\\", mitre_technique_id_count=\\\"1\\\", normalized_risk_object=\\\"34.215.24.225\\\", risk_event_count=\\\"14\\\", risk_object=\\\"34.215.24.225\\\", risk_object_type=\\\"system\\\", risk_score=\\\"1120\\\", risk_threshold=\\\"100\\\", severity=\\\"critical\\\", orig_source=\\\"Network - Unusual Volume of Outbound Traffic By Src - Rule\\\", source_count=\\\"1\\\", orig_tag=\\\"modaction_result\\\"'\", output=\"A natural language summary of the notable.\")\n",
      "orig finding_summarizer\n",
      "32 Write a summary of this notable for my boss '1701478355, search_name=\"Risk - 24 Hour Risk Threshold Exceeded - Rule\", all_risk_objects=\"34.215.24.225\", annotations.mitre_attack=\"T1030\", annotations.mitre_attack.mitre_tactic_id=\"TA0010\", annotations.mitre_attack.mitre_technique_id=\"T1030\", info_max_time=\"1701477600.000000000\", info_min_time=\"1701391200.000000000\", info_search_time=\"1701478354.039744000\", mitre_tactic_id_count=\"1\", mitre_technique_id_count=\"1\", normalized_risk_object=\"34.215.24.225\", risk_event_count=\"14\", risk_object=\"34.215.24.225\", risk_object_type=\"system\", risk_score=\"1120\", risk_threshold=\"100\", severity=\"critical\", orig_source=\"Network - Unusual Volume of Outbound Traffic By Src - Rule\", source_count=\"1\", orig_tag=\"modaction_result\"'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp finding_summarizer(user_input=\"Write a summary of this notable for my boss '1701478355, search_name=\\\"Risk - 24 Hour Risk Threshold Exceeded - Rule\\\", all_risk_objects=\\\"34.215.24.225\\\", annotations.mitre_attack=\\\"T1030\\\", annotations.mitre_attack.mitre_tactic_id=\\\"TA0010\\\", annotations.mitre_attack.mitre_technique_id=\\\"T1030\\\", info_max_time=\\\"1701477600.000000000\\\", info_min_time=\\\"1701391200.000000000\\\", info_search_time=\\\"1701478354.039744000\\\", mitre_tactic_id_count=\\\"1\\\", mitre_technique_id_count=\\\"1\\\", normalized_risk_object=\\\"34.215.24.225\\\", risk_event_count=\\\"14\\\", risk_object=\\\"34.215.24.225\\\", risk_object_type=\\\"system\\\", risk_score=\\\"1120\\\", risk_threshold=\\\"100\\\", severity=\\\"critical\\\", orig_source=\\\"Network - Unusual Volume of Outbound Traffic By Src - Rule\\\", source_count=\\\"1\\\", orig_tag=\\\"modaction_result\\\"'\", output=\"A natural language summary of the notable.\")\n",
      "orig finding_summarizer\n",
      "33 Can you simplify this '1701478355, search_name=\"Risk - 24 Hour Risk Threshold Exceeded - Rule\", all_risk_objects=\"34.215.24.225\", annotations.mitre_attack=\"T1030\", annotations.mitre_attack.mitre_tactic_id=\"TA0010\", annotations.mitre_attack.mitre_technique_id=\"T1030\", info_max_time=\"1701477600.000000000\", info_min_time=\"1701391200.000000000\", info_search_time=\"1701478354.039744000\", mitre_tactic_id_count=\"1\", mitre_technique_id_count=\"1\", normalized_risk_object=\"34.215.24.225\", risk_event_count=\"14\", risk_object=\"34.215.24.225\", risk_object_type=\"system\", risk_score=\"1120\", risk_threshold=\"100\", severity=\"critical\", orig_source=\"Network - Unusual Volume of Outbound Traffic By Src - Rule\", source_count=\"1\", orig_tag=\"modaction_result\"'?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp finding_summarizer(user_input=\"1701478355, search_name=\\\"Risk - 24 Hour Risk Threshold Exceeded - Rule\\\", all_risk_objects=\\\"34.215.24.225\\\", annotations.mitre_attack=\\\"T1030\\\", annotations.mitre_attack.mitre_tactic_id=\\\"TA0010\\\", annotations.mitre_attack.mitre_technique_id=\\\"T1030\\\", info_max_time=\\\"1701477600.000000000\\\", info_min_time=\\\"1701391200.000000000\\\", info_search_time=\\\"1701478354.039744000\\\", mitre_tactic_id_count=\\\"1\\\", mitre_technique_id_count=\\\"1\\\", normalized_risk_object=\\\"34.215.24.225\\\", risk_event_count=\\\"14\\\", risk_object=\\\"34.215.24.225\\\", risk_object_type=\\\"system\\\", risk_score=\\\"1120\\\", risk_threshold=\\\"100\\\", severity=\\\"critical\\\", orig_source=\\\"Network - Unusual Volume of Outbound Traffic By Src - Rule\\\", source_count=\\\"1\\\", orig_tag=\\\"modaction_result\\\"\")\n",
      "orig finding_summarizer\n",
      "34 Explain this finding to me '1701478355, search_name=\"Risk - 24 Hour Risk Threshold Exceeded - Rule\", all_risk_objects=\"34.215.24.225\", annotations.mitre_attack=\"T1030\", annotations.mitre_attack.mitre_tactic_id=\"TA0010\", annotations.mitre_attack.mitre_technique_id=\"T1030\", info_max_time=\"1701477600.000000000\", info_min_time=\"1701391200.000000000\", info_search_time=\"1701478354.039744000\", mitre_tactic_id_count=\"1\", mitre_technique_id_count=\"1\", normalized_risk_object=\"34.215.24.225\", risk_event_count=\"14\", risk_object=\"34.215.24.225\", risk_object_type=\"system\", risk_score=\"1120\", risk_threshold=\"100\", severity=\"critical\", orig_source=\"Network - Unusual Volume of Outbound Traffic By Src - Rule\", source_count=\"1\", orig_tag=\"modaction_result\"'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp finding_summarizer(user_input=\"Explain this finding to me '1701478355, search_name=\\\"Risk - 24 Hour Risk Threshold Exceeded - Rule\\\", all_risk_objects=\\\"34.215.24.225\\\", annotations.mitre_attack=\\\"T1030\\\", annotations.mitre_attack.mitre_tactic_id=\\\"TA0010\\\", annotations.mitre_attack.mitre_technique_id=\\\"T1030\\\", info_max_time=\\\"1701477600.000000000\\\", info_min_time=\\\"1701391200.000000000\\\", info_search_time=\\\"1701478354.039744000\\\", mitre_tactic_id_count=\\\"1\\\", mitre_technique_id_count=\\\"1\\\", normalized_risk_object=\\\"34.215.24.225\\\", risk_event_count=\\\"14\\\", risk_object=\\\"34.215.24.225\\\", risk_object_type=\\\"system\\\", risk_score=\\\"1120\\\", risk_threshold=\\\"100\\\", severity=\\\"critical\\\", orig_source=\\\"Network - Unusual Volume of Outbound Traffic By Src - Rule\\\", source_count=\\\"1\\\", orig_tag=\\\"modaction_result\\\"'\", output=\"A natural language summary of the incident.\")\n",
      "orig finding_summarizer\n",
      "35 Summarize this '1701478355, search_name=\"Risk - 24 Hour Risk Threshold Exceeded - Rule\", all_risk_objects=\"34.215.24.225\", annotations.mitre_attack=\"T1030\", annotations.mitre_attack.mitre_tactic_id=\"TA0010\", annotations.mitre_attack.mitre_technique_id=\"T1030\", info_max_time=\"1701477600.000000000\", info_min_time=\"1701391200.000000000\", info_search_time=\"1701478354.039744000\", mitre_tactic_id_count=\"1\", mitre_technique_id_count=\"1\", normalized_risk_object=\"34.215.24.225\", risk_event_count=\"14\", risk_object=\"34.215.24.225\", risk_object_type=\"system\", risk_score=\"1120\", risk_threshold=\"100\", severity=\"critical\", orig_source=\"Network - Unusual Volume of Outbound Traffic By Src - Rule\", source_count=\"1\", orig_tag=\"modaction_result\"'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp finding_summarizer(user_input=\"1701478355, search_name=\\\"Risk - 24 Hour Risk Threshold Exceeded - Rule\\\", all_risk_objects=\\\"34.215.24.225\\\", annotations.mitre_attack=\\\"T1030\\\", annotations.mitre_attack.mitre_tactic_id=\\\"TA0010\\\", annotations.mitre_attack.mitre_technique_id=\\\"T1030\\\", info_max_time=\\\"1701477600.000000000\\\", info_min_time=\\\"1701391200.000000000\\\", info_search_time=\\\"1701478354.039744000\\\", mitre_tactic_id_count=\\\"1\\\", mitre_technique_id_count=\\\"1\\\", normalized_risk_object=\\\"34.215.24.225\\\", risk_event_count=\\\"14\\\", risk_object=\\\"34.215.24.225\\\", risk_object_type=\\\"system\\\", risk_score=\\\"1120\\\", risk_threshold=\\\"100\\\", severity=\\\"critical\\\", orig_source=\\\"Network - Unusual Volume of Outbound Traffic By Src - Rule\\\", source_count=\\\"1\\\", orig_tag=\\\"modaction_result\\\"\")\n",
      "orig finding_summarizer\n",
      "36 Write a final report for worknotes_1242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp investigation_report\n",
      "orig investigation_report\n",
      "37 Generate an investigation report for worknotes_1242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp [investigation_report(user_input=\"Generate an investigation report for worknotes_1242\")]\n",
      "orig investigation_report\n",
      "38 Create a final investigation report that i can submit for investigation worknotes_1234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp [investigation_report(user_input=\"Create a final investigation report that i can submit for investigation worknotes_1234\")]\n",
      "orig investigation_report\n",
      "39 Can you make a final report for this investigation 12334.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp [investigation_report(user_input=\"Can you make a final report for this investigation 12334\")]\n",
      "orig investigation_report\n",
      "40 Final investigation report for \"work_notes\": \"Alert Name: Excessive Data Transfer to External Server\\n\\nSource Host: endpoint001.company.com\\nIP: 10.5.22.17\\nUsername: jsmith\\n\\nDestination Host: external-server.com\\nIP: 1.2.3.4\\n\\nDetails:\\n- The intrusion detection system detected an unusually large amount of data being transferred from endpoint001 to external-server.com over port 443 (HTTPS)\\n- The connection was initiated by user jsmith at 14:23 UTC today\\n- Over the last 20 minutes, more than 10 GB of data has been transferred outbound\\n- This is significantly higher than the normal traffic profile for this host and user\\n- The excessive data transfer could indicate a potential data exfiltration in progress\\n\\nSeverity: High\\n\\nLooking up the IP address 10.5.22.17 in the network settings, the hostname mapped to that IP is endpoint001.company.com.\\n\\nLooking up user jsmith in the employee directory, I see:\\n\\nFull name: John Smith\\nTitle: Senior Systems Analyst\\nDepartment: IT Operations\\n\\nJohn Smith works in the IT department and has elevated access to systems and data as part of his role managing infrastructure and providing technical support.\\n\\nIs external-server.com a legitimate company?\\n\\nLet me check on external-server.com...\\n\\nI did a WHOIS lookup on the domain name and it is registered to a company called \\\"Cloud Storage LLC\\\" based in another country. Searching our network logs, I don't see any previous connections or authorized business relationship between our company and external-server.com or Cloud Storage LLC.\\n\\nBased on this, external-server.com does not appear to be a legitimate business partner and any communication with them would be suspicious.\\n\\nOk, let's escalate this alert to an investigation.\\n\\nUnderstood, I have escalated this alert to an investigation within our investigation response tracking system. The investigation has been categorized as \\\"Potential Data Exfiltration\\\" and assigned high priority based on the suspicious nature of the activity.\\n\\nThe investigation number is IC-8392.\\n\\nThe investigation report now contains the alert details as well as the investigation notes so far, including:\\n- Host and user information\\n- Large amount of data transferred\\n- Destination is an external server not related to our business\\n\\nI have also added you as the investigation handler to begin further investigation and containment. Let me know if you need any other information added to the investigation record or have additional actions for me to take at this time.\\n\\nWhat accounts were logged into endpoint001 at the time of the alert?\\n\\nChecking the authentication logs for endpoint001 at the time of the alert, I see that the following user accounts were logged in:\\n\\n- jsmith\\n- mjohnson (Mark Johnson, IT Support)\\n- svc_backup (Service account for backup software)\\n\\nJohn Smith's user account was the one actively initiating the suspicious connection to external-server.com. The other accounts were likely just logged in from previous sessions but do not appear directly involved in this investigation.\\n\\nWhere was jsmith logged in from?\\n\\nChecking the connection logs, user jsmith was logged into endpoint001 from the IP address 10.5.21.23. Looking up that IP in DHCP logs, it corresponds to a desktop in the IT department assigned to John Smith. So it appears jsmith initiated the connection from his own desk. There's no indication of his credentials being compromised or suspicious logins from other locations.\\n\\nPlease add the time of that connection to the investigation ticket.\\n\\nI've updated the investigation ticket with the time that John Smith logged in from his desk IP prior to initiating the suspicious connection. The log shows:\\n\\n10/13/2023 13:17:02 - User jsmith authenticated to endpoint001 from IP 10.5.21.23\\n\\nI'll continue updating the investigation ticket with any other relevant information we find during this investigation. Please let me know if you need anything else added or have additional questions.\\n\\nI just called John Smith and he confirmed that there was a legitimate business reason for this unexpected data transfer. He was sharing some authorized information with a vendor who uses external-server.com for large data transfers. Please update the ticket and close the investigation as a benign true positive.\\n\\nUnderstood. I have updated the investigation ticket with the notes from your call with John Smith indicating this was an authorized data transfer that was falsely flagged as suspicious.\\n\\nI have closed the investigation as a benign true positive alert. The notes have been updated to document that the investigation revealed this was legitimate activity, with details on the business justification provided by John Smith.\\n\\nThank you for taking the time to thoroughly investigate this alert. Closing out benign investigations properly helps maintain the accuracy of our threat detection systems over time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp investigation_report\n",
      "orig investigation_report\n",
      "41 write SPL to look at events in _internal index in last 15 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp [spl_writer(intent=\"write SPL to look at events in _internal index in last 15 minutes\")]\n",
      "orig spl_writer\n",
      "42 Generated spl search index=_internal earliest=-2d did not produce any results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp The given function \"spl_writer\" can be used to convert the natural language request into an SPL query. However, the provided query is already in SPL format, so no conversion is needed. The query \"Generated spl search index=_internal earliest=-2d did not produce any results\" is a valid SPL query that can be executed directly. Therefore, the function \"spl_writer\" is not required in this case.\n",
      "orig spl_writer\n",
      "43 can you summarize the findings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp finding_summarizer(user_input=\"can you summarize the findings\")\n",
      "orig finding_summarizer\n",
      "44 How can I remediate Qbot trojan infection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "45 Show all risk events exceeding a threshold of 90 for linux-2 in the past 24 hours, with associated metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp [spl_writer(intent=\"Show all risk events exceeding a threshold of 90 for linux-2 in the past 24 hours, with associated metadata\")]\n",
      "orig spl_writer\n",
      "46 Who are the users associated with the risk events for linux-2 in the past 24 hours?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp [spl_writer(intent=\"get users associated with risk event in past 24 hours for linux-2\")]\n",
      "orig spl_writer\n",
      "47 write SPL to look at events in _internal index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp [spl_writer(intent=\"write SPL to look at events in _internal index\")]\n",
      "orig spl_writer\n",
      "48 Generated spl search index=cim_modactions sourcetype=modular_alerts:risk dest=\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp The provided query is a Splunk search query, and it does not match any of the functions listed. Therefore, the appropriate function to use is `spl_writer`.\n",
      "orig spl_writer\n",
      "49 List all risk events associated with linux-2 in the past 24 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp [spl_writer(intent=\"List all risk events associated with linux-2 in the past 24 hours\")]\n",
      "orig spl_writer\n",
      "50 www.rediff.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "51 Generate investigation report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp [investigation_report(user_input=\"Generate investigation report\")]\n",
      "orig investigation_report\n",
      "52 Discover AI assistant skills\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "53 can you recommend next steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp conversation_response\n",
      "orig conversation_response\n",
      "54 lookup all activity of this affected asset\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     14\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m tmp\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;28mlen\u001b[39m(inputs[\u001b[38;5;241m0\u001b[39m]):], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m end\u001b[38;5;241m=\u001b[39m time()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation/utils.py:2255\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2247\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2248\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2249\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2250\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2251\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2252\u001b[0m     )\n\u001b[1;32m   2254\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2256\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2260\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2262\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2267\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2268\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2269\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2274\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2275\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation/utils.py:3243\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3240\u001b[0m         model_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_compiled_call(generation_config\u001b[38;5;241m.\u001b[39mcompile_config)\n\u001b[1;32m   3242\u001b[0m is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 3243\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_unfinished_sequences\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis_peer_finished\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\n\u001b[1;32m   3245\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   3246\u001b[0m     \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[1;32m   3247\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   3249\u001b[0m     \u001b[38;5;66;03m# prepare variable output controls (note: some models won't accept all output controls)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation/utils.py:2453\u001b[0m, in \u001b[0;36mGenerationMixin._has_unfinished_sequences\u001b[0;34m(self, this_peer_finished, synced_gpus, device, cur_len, max_length)\u001b[0m\n\u001b[1;32m   2451\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m this_peer_finished_flag\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   2452\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# inference\n",
    "from time import time\n",
    "responses=[]\n",
    "latency=[]\n",
    "for i in range(len(input_data)):\n",
    "    print(i, input_data[i])\n",
    "    query = input_data[i]\n",
    "    \n",
    "    messages = [\n",
    "        {'role': 'system', 'content': prompt},\n",
    "        {'role': 'user', 'content': query}\n",
    "    ]\n",
    "    start = time()\n",
    "    inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
    "    tmp=tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\n",
    "    end= time()\n",
    "    responses.append([tmp])\n",
    "    latency.append(end-start)\n",
    "    print(\"resp\",tmp)\n",
    "    print(\"orig\",labels[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89c24bd-2f97-4c64-b146-c6ab24566643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(2.5881452427970038)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(latency))\n",
    "import numpy as np\n",
    "np.mean(np.array(latency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "927f256b-dc5a-4d09-b0dc-023b721488e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_strings(response):\n",
    "    keywords=[\"investigation_report\", \"conversation_response\", \"spl_writer\", \"finding_summarizer\"]\n",
    "    result=[]\n",
    "    for item in response:\n",
    "        found=[kw for kw in keywords if kw in str(item)]\n",
    "        if len(found)>1:\n",
    "            result.append([\"conversation_response\"][0])\n",
    "        elif found:\n",
    "            result.append(found[0])\n",
    "        else:\n",
    "            result.append([\"conversation_response\"][0])\n",
    "    return result\n",
    "            \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fe3d312-3c27-4213-8319-8149bf30ace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'finding_summarizer', 'conversation_response', 'investigation_report', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'spl_writer', 'spl_writer', 'spl_writer', 'spl_writer', 'conversation_response', 'spl_writer', 'spl_writer', 'spl_writer', 'spl_writer', 'spl_writer', 'finding_summarizer', 'finding_summarizer', 'finding_summarizer', 'finding_summarizer', 'finding_summarizer', 'finding_summarizer', 'finding_summarizer', 'finding_summarizer', 'finding_summarizer', 'finding_summarizer', 'investigation_report', 'investigation_report', 'investigation_report', 'investigation_report', 'investigation_report', 'spl_writer', 'spl_writer', 'finding_summarizer', 'conversation_response', 'spl_writer', 'spl_writer', 'spl_writer', 'spl_writer', 'spl_writer', 'conversation_response', 'investigation_report', 'conversation_response', 'conversation_response', 'spl_writer', 'conversation_response', 'conversation_response', 'spl_writer', 'spl_writer', 'spl_writer', 'conversation_response', 'spl_writer', 'spl_writer', 'spl_writer', 'spl_writer', 'conversation_response', 'spl_writer', 'investigation_report', 'spl_writer', 'spl_writer', 'investigation_report', 'investigation_report', 'spl_writer', 'conversation_response', 'conversation_response', 'spl_writer', 'spl_writer', 'conversation_response', 'conversation_response', 'conversation_response', 'spl_writer', 'spl_writer', 'conversation_response', 'conversation_response', 'spl_writer', 'spl_writer', 'conversation_response', 'spl_writer', 'conversation_response', 'spl_writer', 'spl_writer', 'spl_writer', 'spl_writer', 'spl_writer', 'spl_writer', 'spl_writer', 'conversation_response', 'investigation_report', 'conversation_response', 'conversation_response', 'spl_writer', 'conversation_response', 'conversation_response', 'finding_summarizer', 'finding_summarizer', 'conversation_response', 'conversation_response', 'spl_writer', 'spl_writer', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'finding_summarizer', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'spl_writer', 'spl_writer', 'finding_summarizer', 'spl_writer', 'spl_writer', 'spl_writer', 'spl_writer', 'conversation_response', 'spl_writer', 'conversation_response', 'finding_summarizer', 'spl_writer', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'spl_writer', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'investigation_report', 'conversation_response', 'conversation_response', 'finding_summarizer', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response', 'conversation_response']\n"
     ]
    }
   ],
   "source": [
    "responses_parsed=check_strings(responses)\n",
    "print(responses_parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ed973ee-e3e7-402e-8735-446ec3efa2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels=[]\n",
    "for i in range(len(labels)):\n",
    "    true_labels.append(labels[i])\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e0d491c-1d32-4f3b-b74f-5e352d6289be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9482758620689655\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_acc(extracted_labels,true_labels):\n",
    "    correct=sum(set(pred)==set(actual) for pred,actual in zip(extracted_labels,true_labels))\n",
    "    return correct/len(true_labels) \n",
    "print(get_acc(responses_parsed,true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3fdd7af-92bb-4665-8b1e-ae4628b9b83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "conversation_response Search for security investigations like multiple login failures from a single IP address.\n",
      "spl_writer\n",
      "60\n",
      "conversation_response show me all the risk events for this investigation\n",
      "spl_writer\n",
      "74\n",
      "conversation_response what spl could i use to filter these results for commdline that used the curl utility\n",
      "spl_writer\n",
      "88\n",
      "conversation_response Why didnt you generate an SPL\n",
      "spl_writer\n",
      "117\n",
      "conversation_response Has this entity been part of other investigations recently ?\n",
      "spl_writer\n",
      "119\n",
      "conversation_response what findings are linked to this investigation\n",
      "finding_summarizer\n",
      "134\n",
      "finding_summarizer how many findings are in this incident\n",
      "conversation_response\n",
      "138\n",
      "conversation_response get all risk objects listed in this investigation\n",
      "conversation_response or spl_writer\n",
      "151\n",
      "conversation_response What are the MITRE ATT&CK techniques associated with this finding?\n",
      "conversation_response or findings_summarizer\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(true_labels)):\n",
    "    if true_labels[i] != responses_parsed[i]:\n",
    "        print(i)\n",
    "        print(responses_parsed[i],input_data[i])\n",
    "        print(true_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da84979-9a71-4580-afce-a3b6083e67f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "from pathlib import Path\n",
    "output_directory=\"../../grading/data/v2\"\n",
    "pd.DataFrame({\n",
    "    \"responses\": responses,\n",
    "    \"parsed_responses\":responses_parsed,\n",
    "    \"label\":true_labels,\n",
    "    \"inputs\":input_data,\n",
    "    \"latency\":latency\n",
    "    \n",
    "\n",
    "     }).to_csv(Path(output_directory, \"responses_new_watt.csv\"), index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "114a485e-32ae-4964-92a7-62772f34b40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec44827f-6139-412b-80ee-0cfb875aeabb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
